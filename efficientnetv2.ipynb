{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport time\nimport os\nimport random\n\nfrom sklearn import metrics\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import KFold, GroupKFold\nfrom sklearn.utils import shuffle\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom PIL import Image\n\nimport torch\nfrom torch import nn, optim\nimport pl_bolts as pb\nfrom torch.utils.data import Dataset, DataLoader\n\nimport pretrainedmodels as ptm\nimport geffnet as gf\nimport timm\nimport segmentation_models_pytorch as sm\n\nfp16 = True\nscaler = torch.cuda.amp.GradScaler(enabled=fp16)\n\nseed = 0\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True\n\nn = 0\ntorch.cuda.set_device(n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image = pd.read_csv(\"/mnt/md0/siim_covid/train_image_level.csv\")\ntrain_image['id'] = train_image['id'].str.replace(\"_image\", \"\")\ntrain_image[\"sid\"] = train_image.StudyInstanceUID\n\nmeta = pd.read_csv(\"/mnt/md0/siim_covid/meta.csv\").iloc[:6334]\nmeta[\"id\"] = meta['image_id']\nmeta = meta.drop(['image_id'], axis=1)\n\ntrain_image = pd.merge(train_image, meta, on=\"id\")\n\ntrain_study = pd.read_csv(\"/mnt/md0/siim_covid/train_study_level.csv\")\ntrain_study['id'] = train_study['id'].str.replace(\"_study\", \"\")\ntrain_study['sid'] = train_study['id']\ntrain_study = train_study.drop(['id'], axis=1)\n\ndata = pd.merge(train_image, train_study, on=\"sid\")\ndata.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SIIMDataset(Dataset):\n    def __init__(self, data, transforms, path):\n        self.data = data\n        self.transforms = transforms\n        self.path = path\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, i):\n        row = self.data.iloc[i]\n        image = cv2.imread(self.path + row['id'] + \".jpg\")\n        image = (image/255).astype('float32')\n        label = row[8:].values.astype('float32')\n        bboxes = [row['label'].split(\" \")[i:i+6] for i in range(0, \n                    len(self.data.iloc[0]['label'].split(\" \")), 6)]\n        \n        sz = 12\n        h_ratio = sz/row['dim0']\n        w_ratio = sz/row['dim1']\n        st = row['label'].split(\" \")\n        mask = np.zeros((sz, sz, 1)).astype('float32')\n        for s in range(len(st)//6):\n            dims = st[s*6:(s+1)*6][2:]\n            mask[int(float(dims[1])*h_ratio):int(float(dims[3])*h_ratio),\n                 int(float(dims[0])*w_ratio):int(float(dims[2])*w_ratio), :] = 1.\n        \n        if self.transforms: image = self.transforms(image=image)['image']\n        \n        label = np.array([row[8]]).astype(np.float32)\n        \n        return image, label, mask.transpose(2, 0, 1)\n\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ndef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    if keep_ratio: return im.thumbnail((size, size), resample)\n    else: return im.resize((size, size), resample)\n    \nclass TestDataset(Dataset):\n    def __init__(self, data, transforms=None):\n        self.data = data\n        self.transforms = A.Compose([\n            #A.Resize(384, 384),\n            ToTensorV2(),\n            ])\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, i):\n        image = cv2.imread(f'/mnt/md0/siim_covid/test_png/' + self.data[i])\n        image = np.array(resize(image, 384))\n        image = (image/255).astype('float32')\n        \n        if self.transforms: image = self.transforms(image=image)['image']\n        \n        return image\n\ndef create_dataloders(train, test, TRN_BS=32, TST_BS=4, train_augs=None, test_augs=None):\n    \n    if not train_augs:\n        SZ = 384\n        train_augs = A.Compose([\n            A.Resize(SZ, SZ),\n            A.HorizontalFlip(p=0.5),\n            ToTensorV2()\n        ])\n    if not test_augs:\n        test_augs = A.Compose([\n            A.Resize(SZ, SZ),\n            ToTensorV2()\n        ])\n\n    train_dataset = SIIMDataset(train, train_augs, \"/mnt/md0/siim_covid/train/\")\n    test_dataset = SIIMDataset(test, test_augs, \"/mnt/md0/siim_covid/train/\")\n\n    train_loader = DataLoader(train_dataset, batch_size=TRN_BS, shuffle=True, \n                              num_workers=2, worker_init_fn=seed_worker)\n    test_loader = DataLoader(test_dataset, batch_size=TST_BS, shuffle=False, \n                             num_workers=2, worker_init_fn=seed_worker)\n\n    return train_loader, test_loader","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = data[:int(len(data)*0.8)], data[int(len(data)*0.8):]\n\ntrain_loader, test_loader = create_dataloders(train, test)\n\nfor d in test_loader: break\nplt.imshow(d[0][0].numpy().transpose(1, 2, 0))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PcamPool(nn.Module):\n    def __init__(self):\n        super(PcamPool, self).__init__()\n\n    def forward(self, feat_map, prob_map):\n        weight_map = prob_map / prob_map.sum(dim=2, keepdim=True).sum(dim=3, keepdim=True)\n        feat = (feat_map * weight_map).sum(dim=2, keepdim=True).sum(dim=3, keepdim=True)\n        return feat\n    \nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        #self.backbone = nn.Sequential(*[c for c in timm.models.tf_efficientnetv2_m_in21ft1k(pretrained=True).children()][:-2])\n        self.backbone = timm.models.tf_efficientnetv2_l_in21ft1k(pretrained=True)\n        \n        self.b0 = nn.Sequential(\n            self.backbone.conv_stem,\n            self.backbone.bn1,\n            self.backbone.act1,\n        )\n        \n        self.b1 = self.backbone.blocks[0]\n        self.b2 = self.backbone.blocks[1]\n        self.b3 = self.backbone.blocks[2]\n        self.b4 = self.backbone.blocks[3]\n        \n        self.b5 = self.backbone.blocks[4]\n        self.b6 = self.backbone.blocks[5]\n        self.b7 = self.backbone.blocks[6]\n        self.b8 = nn.Sequential(\n            self.backbone.conv_head,\n            self.backbone.bn2,\n            self.backbone.act2,\n        )\n        \n        self.cam_ = nn.Conv1d(1280, 1, (1, 1))\n        \n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        self.maxpool = nn.AdaptiveMaxPool2d(1)\n        self.pcampool = PcamPool()\n        self.flatten = nn.Flatten()\n        self.softmax = nn.Softmax(-1)\n        self.sigmoid = nn.Sigmoid()\n        \n        f = 1280\n        \n        self.classifier = nn.Linear(f*2, 1)\n    \n    def forward(self, inp):\n        #feats = self.backbone(inp)\n        \n        x = self.b0(inp) #torch.Size([4, 24, 192, 192])\n        x = self.b1(x) #torch.Size([4, 24, 192, 192])\n        x = self.b2(x) #torch.Size([4, 48, 96, 96])\n        x = self.b3(x) #torch.Size([4, 80, 48, 48])\n        \n        #pre_meta = self.flatten(torch.mean(x, axis=1))\n        #meta = self.meta(pre_meta)\n        \n        x = self.b4(x) #torch.Size([4, 160, 24, 24])\n        \n        x = self.b5(x) #torch.Size([4, 176, 24, 24])\n        \n        x = self.b6(x) #torch.Size([4, 304, 12, 12])\n        x = self.b7(x) #torch.Size([4, 512, 12, 12])\n        feats = self.b8(x) # torch.Size([4, 1280, 12, 12])\n        \n        #sh = feats.shape[2:]\n        #cam_ = self.sigmoid(self.seg_backbone(inp))\n        #cam = nn.functional.interpolate(cam_, sh)\n        cam_ = self.cam_(feats)\n        cam = self.sigmoid(cam_)\n        #print(feats.shape, cam.shape)\n        pcampool = self.flatten(self.pcampool(feats, cam))\n        #print(pcampool.shape)\n        #feats = self.drop20(feats)\n        avgpool = self.flatten(self.avgpool(feats))\n        #maxpool = self.flatten(self.maxpool(feats))\n        catpool = torch.cat([avgpool, pcampool], -1)\n        logits = self.classifier(catpool)\n        \n        return logits, cam_#torch.zeros((inp.shape[0],)).cuda().half()#cam_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model().cuda()\n#model = nn.DataParallel(Model(), device_ids=[0, 1, 2, 3]).cuda()\no = model(d[0].cuda()) #Not doing for saving ram\ntry: print(o)\nexcept: print(\"Not doing for saving ram\")","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(model, loader, criterion, seg_criterion, optimizer, acm=1):\n    model.train()\n    \n    tq = tqdm(loader)\n    \n    running_loss, running_auc = 0., 0.\n    \n    lbls, outs = [], []\n    optimizer.zero_grad()\n    for i, data in enumerate(tq):\n        \n        inputs, labels = data[0], data[1]\n        inputs = inputs.cuda()\n        labels = labels.cuda()\n        if fp16:\n            inputs = inputs.half()\n            labels = labels.half()\n        \n        with torch.cuda.amp.autocast(enabled=fp16):\n            outputs, cams = model(inputs)\n            loss = criterion(outputs, labels) + seg_criterion(cams, data[2].cuda())#criterion(torch.sigmoid(outputs), torch.argmax(labels, 1))\n        \n        scaler.scale(loss).backward()\n        if not i % acm:\n            scaler.step(optimizer)\n            optimizer.zero_grad()\n        scaler.update()\n        \n        running_loss += loss.item()\n        labels, outputs = labels.detach().cpu(), outputs.detach().cpu()\n        try: running_auc += roc_auc_score(np.concatenate(labels.numpy(), 0), np.concatenate(outputs.numpy(), 0))\n        except: running_auc += .5\n        \n        tq.set_postfix(loss=running_loss/(i+1), auc=running_auc/(i+1))\n        \n        lbls.append(labels.cpu().detach().numpy())\n        outs.append(outputs.cpu().detach().numpy())\n    \n    return np.concatenate(lbls), np.concatenate(outs), [running_loss/(i+1), running_auc/(i+1)] \n\ndef test_fn(model, loader, criterion, seg_criterion):\n    model.eval()\n    \n    tq = tqdm(loader)\n    \n    running_loss, running_auc = 0., 0.\n    \n    lbls, outs = [], []\n    \n    for i, data in enumerate(tq):\n        \n        inputs, labels = data[0], data[1]\n        inputs = inputs.cuda()\n        labels = labels.cuda()\n        if fp16:\n            inputs = inputs.half()\n            labels = labels.half()\n        \n        with torch.cuda.amp.autocast(enabled=fp16):\n            outputs, cams = model(inputs)\n            loss = criterion(outputs, labels) + seg_criterion(cams, data[2].cuda())#criterion(torch.sigmoid(outputs), torch.argmax(labels, 1))\n        \n        running_loss += loss.item()\n        labels, outputs = labels.detach().cpu(), outputs.detach().cpu()\n        try: running_auc += roc_auc_score(np.concatenate(labels.numpy(), 0), np.concatenate(outputs.numpy(), 0))\n        except: running_auc += .5\n        \n        tq.set_postfix(loss=running_loss/(i+1), auc=running_auc/(i+1))\n        \n        lbls.append(labels.cpu().detach().numpy())\n        outs.append(outputs.cpu().detach().numpy())\n        \n    return np.concatenate(lbls), np.concatenate(outs), [running_loss/(i+1), running_auc/(i+1)] ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE = 384\n\ntrain_augs = A.Compose([\n    A.RandomResizedCrop(SIZE, SIZE, scale=(0.3, 1.2)),\n    A.HorizontalFlip(p=0.5),\n    A.Rotate(p=0.5, limit=45),\n    A.RandomBrightnessContrast(p=.5),\n    #A.RandomGamma(p=0.5),\n    A.Cutout(p=0.25, num_holes=4, max_h_size=64, max_w_size=64),\n    \n    ToTensorV2()\n])\n\ntest_augs = A.Compose([\n    A.Resize(SIZE, SIZE),\n    ToTensorV2()\n])\n\nTRN_BS = 32\nacm = 1\nTST_BS = 4\nEPOCHS = 20\n\nscores = []\n\nDIR = \"/mnt/md0/siim_covid/models/\"\nBACKBONE = \"effv2l_2cls\"\nversion = \"2\"\n\ntry: os.mkdir(f\"{DIR}/{BACKBONE}_v{version}/\")\nexcept: pass\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\nfor i, (d1, d2) in enumerate(GroupKFold(n_splits=5).split(data, groups=data.id.tolist())):\n    print(f\"FOLD {i}\")\n    \n    model = nn.DataParallel(Model(), device_ids=[n, n+1]).cuda()\n    \n    curr_best = -np.inf\n    \n    train, test = data.iloc[d1], data.iloc[d2]\n    train_loader, test_loader = create_dataloders(train, test, TRN_BS, TST_BS, train_augs, test_augs)\n    \n    criterion = nn.BCEWithLogitsLoss()#nn.CrossEntropyLoss\n    seg_criterion = nn.BCEWithLogitsLoss()\n    \n    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n    scheduler = pb.optimizers.LinearWarmupCosineAnnealingLR(optimizer,\n                                                            warmup_epochs=3, max_epochs=EPOCHS,\n                                                            warmup_start_lr=1e-4, eta_min=1e-6)\n\n    for _ in range(EPOCHS):\n        print(f\"TRAINING EPOCH {_} LR: {get_lr(optimizer)}\")\n        trn_lbls, trn_outs, metrics = train_fn(model, train_loader, criterion, seg_criterion, optimizer, acm)\n        print(f\"TESTING EPOCH {_}\")\n        tst_lbls, tst_outs, metrics = test_fn(model, test_loader, criterion, seg_criterion)\n        score = average_precision_score(tst_lbls[:, 0], tst_outs[:, 0]) * 1/3\n        \n        if score > curr_best:\n            print(\"NEW BEST: {:.3f}\".format(score))\n            best_state = model\n            curr_best = score\n        \n        scheduler.step()\n    \n    scores.append(curr_best)\n    \n    \n    try: torch.jit.save(torch.jit.script(best_state.module), f\"{DIR}/{BACKBONE}_v{version}/f{i}.pth\")\n    except:\n        try: torch.save(best_state.module.state_dict(), f\"{DIR}/{BACKBONE}_v{version}/f{i}_st.pth\")\n        except: print(\"Not Saved\")\n    open(f\"{DIR}/{BACKBONE}_v{version}/f{i}.txt\", \"w\").write(str(curr_best))\n    \n    sub = pd.read_csv(\"/mnt/md0/siim_covid/updated_sample_submission.csv\")\n    sub.dcm_path = sub['dcm_path'].str.replace(\"/kaggle/input/siim-covid19-detection/test/\", \"\").str.split(\"/\")\n    \n    images = [p[-1].replace('.dcm', '.png') for p in sub.dcm_path[1214:]]\n    test_dataset = TestDataset(images)\n    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4)\n    preds = []\n    for d in tqdm(test_loader):\n        outs = []\n        with torch.no_grad():\n                #o = torch.sigmoid(m(d.cuda())).detach().cpu().numpy()\n            o = torch.sigmoid(best_state(d.cuda())[0]).detach().cpu().numpy()\n            outs.append(o)\n        outs = np.mean(outs, 0)\n        preds.append(outs)\n    preds = np.concatenate(preds)\n    \n    sub_df = sub.copy()\n    sub = sub[1214:]\n    sub = sub.reset_index()\n    sub['none'] = 0\n    sub[['none']] = preds\n    for j in range(1263):\n        none = sub.loc[j,'none']\n        sub.loc[j, 'PredictionString'] = f'none {none} 0 0 1 1'\n\n    sub_df = sub_df[:1214]\n    sub_df = sub_df.append(sub).reset_index()[['id', 'PredictionString']]\n\n    sub_df.to_csv(f\"{DIR}/{BACKBONE}_v{version}/f{i}_sub.csv\", index=False)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DIR = \"/mnt/md0/siim_covid/models/\"\nBACKBONE = \"effv2l_2cls\"\nversion = '2'\nsubs = [pd.read_csv(f\"{DIR}/{BACKBONE}_v{version}/{f}\") for f in os.listdir(f\"{DIR}/{BACKBONE}_v{version}/\") if f.endswith(\"_sub.csv\")]\nlabels = []\nfor sub in subs:\n    cache = []\n    for _ in range(len(preds)):\n        predstring = sub.loc[1214+_].PredictionString.split(\" \")\n        cache.append([predstring[1]])\n    labels.append(cache)\nlabels = np.mean(np.array(labels).astype(np.float32), 0)\n\nsub = pd.read_csv(\"/mnt/md0/siim_covid/updated_sample_submission.csv\")\n\nsub_df = sub.copy()\nsub = sub[1214:]\n\nfor j in tqdm(range(len(preds))):\n    none = labels[j][0]\n    sub.loc[1214+j, 'PredictionString'] = f'none {none} 0 0 1 1'\n\nsub_df[1214:] = sub\nsub_df =  sub_df[['id', 'PredictionString']]\n#sub = sub.append(sub_df[1214:])[['id', 'PredictionString']]\n    \nsub_df.to_csv(f\"{DIR}/{BACKBONE}_v{version}/none_sub.csv\", index=False)","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}